{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep dive into `IPPy`\n",
    "\n",
    "`IPPy` is a simple library, developed by me specifically for this course (and to support me during my experiments for papers). It includes multiple modules:\n",
    "\n",
    "- `nn`: contains functions to easy define complex neural network models, such as UNet, ViT, and others, with a flexible design.\n",
    "- `solvers`: implements a few optimization algorithms already discussed in the first module of this course, such as the `ChambollePock` algorithm for TV minimization, the `SGP` algorithm for smoothed-TV regularization, and others.\n",
    "- `operators`: implements multiple operators (we will check some of them below) specifically designed to work well with pytorch tensors. Not only they are developed so that they can efficiently work with batched, multidimensional data, but they also implement gradient tracking, useful to backpropagate the gradient back from the output to the input of the inverse process. This is useful in applications such as Algorithm Unrolling or Deep Generative Prior (DGP).\n",
    "\n",
    "The code for `IPPy` can be simply dowloaded from my Github page at: [https://github.com/devangelista2/IPPy](https://github.com/devangelista2/IPPy).\n",
    "\n",
    "```{image} /imgs/IPPy-structure.png\n",
    ":width: 600px\n",
    ":align: center\n",
    "```\n",
    "\n",
    "## Introduction and requirements\n",
    "\n",
    "IPPy is built upon a few commonly used libraries for tensor manipulation, linear algebra, Computed Tomography, neural networks and visualization. Here is a list of the libraries you need to install to make IPPy run smoothly:\n",
    "\n",
    "- `numpy`\n",
    "- `numba`\n",
    "- `astra-toolbox`\n",
    "- `scikit-image`\n",
    "- `PIL`\n",
    "- `matplotlib`\n",
    "\n",
    "Moreover, it is **required** to have access to a cuda GPU, both for training neural network models and for fast Computed Tomography simulations. In particular, some `astra-toolbox` operators won't work if CUDA is not available.\n",
    "\n",
    "```{warning}\n",
    "In case one has no access to a `cuda` GPU, it can be also installed the `cpu` version of `astra-toolbox` (a few geometries won't work in this setup, but it is ok for the topic of this course).\n",
    "```\n",
    "\n",
    "Basically all the required libraries can be simply install with the command:\n",
    "\n",
    "```\n",
    "pip install <PACKAGE_NAME>\n",
    "```\n",
    "\n",
    "or by:\n",
    "\n",
    "```\n",
    "conda install <PACKAGE_NAME>\n",
    "```\n",
    "\n",
    "The only exception is `astra-toolbox`, whose installation instruction can be found in its official documentation website, at: [https://astra-toolbox.com](https://astra-toolbox.com).\n",
    "\n",
    "### Standard tensors\n",
    "\n",
    "As already remarked, all the `IPPy` functions are thought to work with Pytorch tensors. In particular, with what is called a **standardized pytorch tensor**, that is a tensor with the following properties:\n",
    "\n",
    "- Its shape is `(N, c, n_x, n_y)`, where `c` is either equal to 1 or 3.\n",
    "- It is normalized so that its maximum is 1 and its minimum is 0.\n",
    "- Its `ndtype` is `float32`.\n",
    "\n",
    "While most of the functions still works if some of these properties are not satisfied, the obtained results could be artificious.\n",
    "\n",
    "Given that, we can now move to the core of the `IPPy` package: the `operators` module.\n",
    "\n",
    "## The `operators` module\n",
    "\n",
    "An `IPPy` operator is a Python class that simulates the application of a corruption matrix $K$ to an input tensor $x$. The basic `Operator` class is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Operator:\n",
    "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Applies operator using PyTorch autograd wrapper\"\"\"\n",
    "        return OperatorFunction.apply(self, x)\n",
    "\n",
    "    def __matmul__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Matrix-vector multiplication\"\"\"\n",
    "        return self.__call__(x)\n",
    "\n",
    "    def T(self, y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Transpose operator (adjoint)\"\"\"\n",
    "        device = y.device\n",
    "        # Apply adjoint to the batch\n",
    "        return self._adjoint(y).to(device).requires_grad_(True)\n",
    "\n",
    "    def _matvec(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply the operator to a single (c, h, w) tensor\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _adjoint(self, y: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply the adjoint operator to a single (c, h, w) tensor\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `Operator` class implements a few basic methods, such as `__call__`, `__matmul__` and `T` that should not be modified by the user, and two methods that are specific for the kind of operator and should be customized: `_matvec` and `_adjoint`. \n",
    "\n",
    "As you can easily imagine, the `_matvec` method describes how the operator should corrupt the input tensor, i.e. how to compute the forward $K(x)$. Similarly, the `_adjoint` method represents the application of the transposed of the operator, i.e. $K^T(y)$. \n",
    "\n",
    "Note that, thanks to the support of the `OperatorFunction`, each operator needs to be defined only on a tensor of shape `(c, n_x, n_y)`, and it will automatically handle the parallelization over the batch dimension `N` of the input tensor.  \n",
    "\n",
    "### Example: the Negative operator\n",
    "\n",
    "As an example, let's build a **negative** operator, i.e. an operator that reverse the colors of the input image, based on the `Operator` class in `IPPy`. We will consider an image from Mayo's dataset from the previous notebook as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------\n",
    "# This is just for rendering on the website\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#-----------------\n",
    "\n",
    "from IPPy import operators\n",
    "\n",
    "class NegativeOperator(operators.Operator):\n",
    "    def _matvec(self, x):\n",
    "        \"\"\"\n",
    "        Since x is a standardized Tensor (i.e. its in the range [0, 1]), the negative image\n",
    "        can be obtained by simply computing y = 1 - x.\n",
    "        \"\"\"\n",
    "        return 1 - x\n",
    "    \n",
    "    def _adjoint(self, y):\n",
    "        \"\"\"\n",
    "        The adjoint of the negative operator is again x = 1 - y.\n",
    "        \"\"\"\n",
    "        return 1 - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MayoDataset(Dataset):\n",
    "    def __init__(self, data_path, data_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.data_shape = data_shape\n",
    "\n",
    "        # We expect data_path to be like \"./data/Mayo/train\" or \"./data/Mayo/test\"\n",
    "        self.fname_list = glob.glob(f\"{data_path}/*/*.png\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fname_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load the idx's image from fname_list\n",
    "        img_path = self.fname_list[idx]\n",
    "\n",
    "         # To load the image as grey-scale\n",
    "        x = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "        # Convert to numpy array -> (512, 512)\n",
    "        x = np.array(x) \n",
    "\n",
    "        # Convert to pytorch tensor -> (1, 512, 512) <-> (c, n_x, n_y)\n",
    "        x = torch.tensor(x).unsqueeze(0)\n",
    "\n",
    "        # Resize to the required shape\n",
    "        x = transforms.Resize(self.data_shape)(x) # (1, n_x, n_y)\n",
    "\n",
    "        # Normalize in [0, 1] range\n",
    "        x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Get sample image\n",
    "test_data = MayoDataset(data_path=\"../data/Mayo/test\", data_shape=256)\n",
    "x = test_data[0].unsqueeze(0)\n",
    "\n",
    "# Define corruption operator\n",
    "K = NegativeOperator()\n",
    "\n",
    "# Compute negative of x\n",
    "y = K(x)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(x.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(y.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Corrupted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in operators\n",
    "\n",
    "Clearly, `IPPy` implements a few built-in operators commonly used in literature. At this moment, it has built-in support for:\n",
    "\n",
    "- **Computed Tomography** operator: implementing the forward and backward acquisition of a general Computed Tomography projector,\n",
    "- **Image Deblurring** operator: implementing a general Blurring and Deblurring operator, taking as input either a general blurring kernel or the parameters for a built-in Gaussian kernel (specifying the variance and the kernel size), and a Motion kernel (specifying the motion angle and the kernel size);\n",
    "- **Downscaling** operator: which downscale the input image by a given factor.;\n",
    "- **Gradient** operator: mostly used to implement TV-based reconstruction algorithm.\n",
    "\n",
    "But more operators will be added in the future.\n",
    "\n",
    "Let's see how to blur an image with a MotionBlur kernel of specified parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'utilities' from 'IPPy' (C:\\Users\\tivog\\anaconda3\\lib\\site-packages\\IPPy\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPPy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m operators, utilities\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Get sample image from MayoDataset\u001b[39;00m\n\u001b[0;32m      4\u001b[0m x_true \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'utilities' from 'IPPy' (C:\\Users\\tivog\\anaconda3\\lib\\site-packages\\IPPy\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from IPPy import operators, utilities\n",
    "\n",
    "# Get sample image from MayoDataset\n",
    "x_true = test_data[10].unsqueeze(0)\n",
    "\n",
    "# Define MotionBlur operator (with a 45Â° angle)\n",
    "K = operators.Blurring(img_shape=(256, 256), \n",
    "                       kernel_type=\"motion\", \n",
    "                       kernel_size=7, \n",
    "                       motion_angle=45,)\n",
    "\n",
    "# Compute blurred version of x_true\n",
    "y = K(x_true)\n",
    "\n",
    "# Add noise\n",
    "y_delta = y + utilities.gaussian_noise(y, noise_level=0.01)\n",
    "\n",
    "# Compute (just for the sake of the explanation, the transpose)\n",
    "x_T = K.T(y_delta)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(x_true.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(y_delta.squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Corrupted')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(x_T.detach().squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('K^T(y_delta)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to test different operators to see how they work.\n",
    "\n",
    "### Backpropagate through `IPPy` operators\n",
    "\n",
    "A great feature of `IPPy` operators is that they allow backpropagating through them by the usual Pytorch backpropagation. For example, consider the following objective function:\n",
    "\n",
    "$$\n",
    "f(x) = || Kx - y^\\delta ||_2^2,\n",
    "$$\n",
    "\n",
    "and note that:\n",
    "\n",
    "$$\n",
    "\\nabla_x f(x) = 2 * K^T(Kx - y^\\delta).\n",
    "$$\n",
    "\n",
    "This operation can be automatically performed for `IPPy` operators via the `.backward()` method in Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define x_true and track its gradient\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_true \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data\u001b[49m[\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m x_true\u001b[38;5;241m.\u001b[39mrequires_grad_(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Compute y_delta with no gradient tracking\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Define x_true and track its gradient\n",
    "x_true = test_data[10].unsqueeze(0)\n",
    "x_true.requires_grad_(True)\n",
    "\n",
    "# Compute y_delta with no gradient tracking\n",
    "with torch.no_grad():\n",
    "    y = K(x_true)\n",
    "    y_delta = y + utilities.gaussian_noise(y, noise_level=0.005)\n",
    "\n",
    "# Example: compute f(x)\n",
    "f = torch.sum(torch.square(K(x_true) - y_delta))\n",
    "\n",
    "# Compute gradient\n",
    "f.backward()\n",
    "grad_x = x_true.grad\n",
    "print(f\"Grad_x = {torch.norm(grad_x).item():0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This property, while it seems of limited use, will be crucial for basically any hybrid method. We will come back to this later in the course.\n",
    "\n",
    "## The `solvers` module\n",
    "\n",
    "In `IPPy` one can also find a few built-in solvers for regularized least-squares problem, mainly with the aim of comparing the results of neural network predictions with the classical algorithm discussed in the first module of this course.\n",
    "\n",
    "As classical solvers are beyond the scope of this course, we will only report here an example on how to use an `IPPy` solver on the data defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPPy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m solvers, metrics\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define the solver (e.g. ChambollePock)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m solver \u001b[38;5;241m=\u001b[39m solvers\u001b[38;5;241m.\u001b[39mChambollePockTpVUnconstrained(K) \u001b[38;5;66;03m# -> takes as input the operator\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPPy\\solvers.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m operators, metrics, reconstructors\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCGLS\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, A):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPPy\\metrics.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrel_err\u001b[39m(xtik, x):\n\u001b[0;32m      5\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from IPPy import solvers, metrics\n",
    "\n",
    "# Define the solver (e.g. ChambollePock)\n",
    "solver = solvers.ChambollePockTpVUnconstrained(K) # -> takes as input the operator\n",
    "\n",
    "# Compute solution\n",
    "x_rec, _ = solver(y_delta, \n",
    "               lmbda=0.01, \n",
    "               x_true=x_true, \n",
    "               starting_point=torch.zeros_like(x_true),\n",
    "               verbose=False,)\n",
    "\n",
    "print(f\"Reconstruction SSIM: {metrics.SSIM(x_rec, x_true):0.4f}.\")\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(x_true.detach().squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(y_delta.detach().squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Corrupted')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(x_rec.detach().squeeze(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Reconstruction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `nn` module\n",
    "\n",
    "We are finally ready to jump into the main topic of this course, i.e. neural networks and their use for end-to-end image reconstruction. In the remainder of this chapter, we will discuss how to implement a neural network for processing and reconstructing images with `IPPy`, with the aim of recovering the motion-blurred image from the previous example.\n",
    "\n",
    "```{warning}\n",
    "In the following we will learn how to implement a few neural network architectures, such as `CNN` or `UNet`, which we **didn't introduced yet**. For now, just threat them as general neural network used to reconstruct images. We will deeply discuss how they work in the next chapter of this course.\n",
    "```\n",
    "\n",
    "Defining a training a neural network model with `IPPy` is straightforward: just choose one of the available architecture from the `nn` module, set the parameters (or implement one yourself), and you are ready to go!\n",
    "\n",
    "Let's see how to implement a `UNet` model for image reconstruction using `IPPy.nn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPPy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Set device\u001b[39;00m\n\u001b[0;32m      4\u001b[0m device \u001b[38;5;241m=\u001b[39m utilities\u001b[38;5;241m.\u001b[39mget_device()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\IPPy\\nn\\models.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras \u001b[38;5;28;01mas\u001b[39;00m ks\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _simple_models, _unet_models, _NAF_models\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from IPPy.nn import models\n",
    "\n",
    "# Set device\n",
    "device = utilities.get_device()\n",
    "\n",
    "# Defining neural network architecture (IGNORE now)\n",
    "model = models.UNet(ch_in=1, \n",
    "                    ch_out=1,\n",
    "                    middle_ch=[64, 128, 256],\n",
    "                    n_layers_per_block=2,\n",
    "                    down_layers=(\"ResDownBlock\", \"ResDownBlock\"),\n",
    "                    up_layers=(\"ResUpBlock\", \"ResUpBlock\"),\n",
    "                    final_activation=None)\n",
    "\n",
    "# Send model to device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the data (train and test) to train our model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MayoDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Generate train and test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mMayoDataset\u001b[49m(data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/Mayo/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m MayoDataset(data_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/Mayo/test\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m      5\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(train_data, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MayoDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate train and test data\n",
    "train_data = MayoDataset(data_path=\"../data/Mayo/train\", data_shape=256)\n",
    "test_data = MayoDataset(data_path=\"../data/Mayo/test\", data_shape=256)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the training loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m n_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m----> 7\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(params\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Cycle over the epochs\u001b[39;00m\n\u001b[0;32m     10\u001b[0m loss_total \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((n_epochs,))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "#--- Parameters\n",
    "n_epochs = 0\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "\n",
    "# Cycle over the epochs\n",
    "loss_total = torch.zeros((n_epochs,))\n",
    "ssim_total = torch.zeros((n_epochs,))\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Cycle over the batches\n",
    "    epoch_loss = 0.0\n",
    "    ssim_loss = 0.0\n",
    "    for t, x in enumerate(train_loader):\n",
    "        # Send x and y to device\n",
    "        x = x.to(device)\n",
    "\n",
    "        # Compute associated y_delta\n",
    "        y = K(x)\n",
    "        y_delta = y + utilities.gaussian_noise(y, noise_level=0.01)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        x_pred = model(y_delta)\n",
    "        loss = loss_fn(x_pred, x)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update loss\n",
    "        epoch_loss += loss.item()\n",
    "        ssim_loss += metrics.SSIM(x_pred.cpu().detach(), x.cpu().detach())\n",
    "\n",
    "        # Infos\n",
    "        print(\n",
    "            f\"Epoch ({epoch+1} / {n_epochs}) -> Loss = {epoch_loss / (t + 1):0.4f}, \"\n",
    "            + f\"SSIM = {ssim_loss / (t + 1):0.4f}.\",\n",
    "            end=\"\\r\",\n",
    "        )\n",
    "\n",
    "    # Update the history\n",
    "    loss_total[epoch] = epoch_loss / (t + 1)\n",
    "    ssim_total[epoch] = ssim_loss / (t + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is trained, it's recommended to save the final state so that we can re-use it without waiting for the training to finish. This is done by the `trainer` module of `IPPy`, which saves both the final state of the model and a `json` file containing the specification of model architecture, so that you can re-load it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'trainer' from 'IPPy.nn' (C:\\Users\\tivog\\anaconda3\\lib\\site-packages\\IPPy\\nn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPPy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trainer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Save model state\u001b[39;00m\n\u001b[0;32m      4\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave(model, weights_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../weights/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'trainer' from 'IPPy.nn' (C:\\Users\\tivog\\anaconda3\\lib\\site-packages\\IPPy\\nn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from IPPy.nn import trainer\n",
    "\n",
    "# Save model state\n",
    "trainer.save(model, weights_path=\"../weights/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model is straightforward. Just provide the `trainer` with the correct path and it will handle everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mload(weights_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../weights/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model = trainer.load(weights_path=\"../weights/\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can test the loaded model over the test set to see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test on test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, x_test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtest_loader\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Send to device\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     x_test \u001b[38;5;241m=\u001b[39m x_test\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Compute y_delta\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Test on test data\n",
    "for t, x_test in enumerate(test_loader):\n",
    "    # Send to device\n",
    "    x_test = x_test.to(device)\n",
    "\n",
    "    # Compute y_delta\n",
    "    y = K(x_test)\n",
    "    y_delta = y + utilities.gaussian_noise(y, noise_level=0.01)\n",
    "\n",
    "    # Predict with model (without computing the gradient to save memory)\n",
    "    with torch.no_grad():\n",
    "        x_pred = model(y_delta)\n",
    "    \n",
    "    # Visualize the input-output-prediction triplet\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(x_test[0].cpu().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Original')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(y_delta[0].cpu().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Corrupted')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(x_pred[0].cpu().detach().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('K^T(y_delta)')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we learned how to implement, train and test a neural network model, we are ready to get into the details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}