{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-End Image Reconstruction methods\n",
    "\n",
    "We are finally ready to describe more in details the main architecture used for end-to-end image reconstruction with neural networks. In particular, this chapter will focus not only on describing the main architectures commonly used in the literature, namely the Convolutional Neural Network (**CNN**), the **UNet** and the **Vision Transformer (ViT)**, but it will also delve into the detail on **why** some architectural choice is made and in which occasion one may want to slightly modify the default architecture. \n",
    "\n",
    "For the whole chapter we will consider as an example the inverse problem associated with the MotionBlur operator, considering the Mayo's Dataset already introduced in the previous chapter. At the end of this chapter, we will also investigate the Computed Tomography inverse problem, which requires more attention as, differently from the MotionBlur, in Computed Tomography (as well as in SuperResolution, and others), the dimensionality of the measurement $y^\\delta$ is different from the dimensionality of the datum $x_{true}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks\n",
    "\n",
    "Working with images is a completely different task than working with tabular data, not only because the number of features in images is usually way higher than the number of features of tabular data, but also in the way these features should be considered. \n",
    "\n",
    "Indeed, when we analyze an image, the value of one given pixel **alone** is of low importance: we mostly care on the behavior of a set of neighbour pixels which, when taken together, produces a **visible object** in our image. But that's more, sometimes, we also care about more **global** information, i.e. how the object described by the neighbour of pixels interact with the other objects, with the environment, and its relative position inside the image.\n",
    "\n",
    "More formally, if we define a **punctual information** as any information that can be extracted by considering a single pixel, isolated by its context, a **local information** as any information that can be extracted by a small set of neighbour pixels, and a **global information** as any information that requires a global knowledge on the value of each pixels in the image to be extracted, with a context that fullfils the whole image, then we can say than image processing task is mostly based on local and global information, with a very minority of punctual information. \n",
    "\n",
    "From this observation, one can note that the classical MLP architecture, defined by a chain of linear transformation alternated with non-linear activation functions, which processes each pixel as a single, isolated neuron, is meaningless. Indeed, it would be better to consider a network where each **linear** layer is substitued with a layer that takes into consideration **local** information. The simplest mathematical tool achieving this is the **Convolution** operation. \n",
    "\n",
    "```{image} /imgs/convolution.pdf\n",
    ":width: 800px\n",
    ":align: center\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}