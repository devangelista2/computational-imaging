{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0.9899, 0.0761],\n",
      "        [0.7127, 0.7101]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Creating a tensor from a list\n",
    "t1 = torch.tensor([1, 2, 3])\n",
    "print(t1)\n",
    "\n",
    "# Creating a tensor with predefined values\n",
    "t2 = torch.zeros(3, 3)  # 3x3 matrix of zeros\n",
    "t3 = torch.ones(2, 4)   # 2x4 matrix of ones\n",
    "t4 = torch.rand(2, 2)   # 2x2 matrix of random values between 0 and 1\n",
    "\n",
    "print(t2)\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([3, 4])\n",
      "Data type: torch.float32\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "t = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape: {t.shape}\")  # Dimensions of the tensor\n",
    "print(f\"Data type: {t.dtype}\")  # Data type (default is float32)\n",
    "print(f\"Device: {t.device}\")  # CPU or GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6,  8],\n",
      "        [10, 12]])\n",
      "tensor([[ 5, 12],\n",
      "        [21, 32]])\n",
      "tensor([[1.0000, 1.4142],\n",
      "        [1.7321, 2.0000]])\n",
      "tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "y = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# Element-wise operations\n",
    "print(x + y)  # Addition\n",
    "print(x * y)  # Multiplication\n",
    "print(torch.sqrt(x.float()))  # Square root (requires float type)\n",
    "\n",
    "# Matrix multiplication\n",
    "print(x @ y)  # Equivalent to torch.matmul(x, y)\n",
    "\n",
    "# Reshaping tensors\n",
    "z = torch.arange(6).reshape(2, 3)\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Running on CPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # Use GPU\n",
    "    x = x.to(device)\n",
    "    print(f\"Tensor is now on: {x.device}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: -1.798995018005371, y: -0.5979900360107422\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, N=100):\n",
    "        self.x = torch.linspace(-2, 2, N)\n",
    "        self.y = 2 * self.x + 3  # Linear function\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Create dataset instance\n",
    "dataset = SimpleDataset(N=200)\n",
    "\n",
    "# Fetch a single data point\n",
    "idx = 10\n",
    "x_sample, y_sample = dataset[idx]\n",
    "print(f\"x: {x_sample}, y: {y_sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch - x: tensor([-0.8744, -1.2161]), y: tensor([1.2513, 0.5678])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Iterate through batches\n",
    "for batch in dataloader:\n",
    "    x_batch, y_batch = batch\n",
    "    print(f\"Batch - x: {x_batch}, y: {y_batch}\")\n",
    "\n",
    "    break # For site impagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset from sklearn\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features for better training stability\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "y = y.reshape(-1, 1)  # Reshape target to be a column vector\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaliforniaHousingDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create Dataset instances\n",
    "train_dataset = CaliforniaHousingDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CaliforniaHousingDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fc1): Linear(in_features=8, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))  # Apply ReLU activation to first layer\n",
    "        x = self.fc2(x)          # Output layer (no activation for now)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "model = SimpleNN(input_size=8, \n",
    "                 hidden_size=64, \n",
    "                 output_size=1)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_batch: torch.Size([16, 8]). Shape of y_batch: torch.Size([16, 1])\n",
      "Real value: 3.6110000610351562. Model prediction: 0.283534973859787.\n"
     ]
    }
   ],
   "source": [
    "# Sample data from the dataset\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "# Check the shape of the batch\n",
    "print(f\"Shape of x_batch: {x_batch.shape}. Shape of y_batch: {y_batch.shape}\")\n",
    "\n",
    "# Forward pass through the model\n",
    "y_prediction = model(x_batch)\n",
    "\n",
    "# Visualizing a value compared to the real (expected) solution\n",
    "print(f\"Real value: {y_batch[0].item()}. Model prediction: {y_prediction[0].item()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1053, 0.2105, 0.3158, 0.4211, 0.5263, 0.6316, 0.7368, 0.8421,\n",
      "        0.9474, 1.0526, 1.1579, 1.2632, 1.3684, 1.4737, 1.5789, 1.6842, 1.7895,\n",
      "        1.8947, 2.0000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a leaf tensor\n",
    "x = torch.linspace(0, 1, 20, requires_grad=True)\n",
    "\n",
    "# Compute y = x**2\n",
    "y = torch.square(x)\n",
    "\n",
    "# Compute loss = sum(x**2)\n",
    "loss = torch.sum(y)\n",
    "\n",
    "# Compute gradient of the loss\n",
    "loss.backward()\n",
    "\n",
    "# Extract gradient wrt x -> d/dx loss(x^**2) = 2*x\n",
    "g = x.grad\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function (for example, MSE)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (feeding the model parameters into it)\n",
    "# Adam -> variant of SGD algorithm commonly used nowadays\n",
    "#   lr -> \"learning rate\"\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-4)\n",
    "\n",
    "# Set other parameters (e.g. the number of epochs: number of times the training loop is repeated)\n",
    "n_epochs = 50\n",
    "\n",
    "# Epoch cycle\n",
    "for epoch in range(n_epochs):\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    # Training loop\n",
    "    for k, data in enumerate(train_loader):\n",
    "        # Get x, y from data\n",
    "        x, y = data\n",
    "\n",
    "        # Send to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Compute neural network prediction\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # Compare y_pred with the real y\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Compute gradient\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() # Reset the optimizer state: IMPORTANT\n",
    "\n",
    "        # Print out the avg value of the loss\n",
    "        # Commented for site impagination\n",
    "        # print(f\"Epoch: {epoch}. Avg Loss: {loss.item() / (k+1):0.4f}\", end=\"\\r\")\n",
    "    # print()\n",
    "\n",
    "# Saving the model after the cycle\n",
    "torch.save(model.state_dict(), \"path-for-model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 3.2548. True: 3.9080.\n"
     ]
    }
   ],
   "source": [
    "# Disable gradient memorization\n",
    "with torch.no_grad():\n",
    "    # Sample data from the dataset\n",
    "    x_batch, y_batch = next(iter(train_loader))\n",
    "\n",
    "    # Send to device\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    y_prediction = model(x_batch)\n",
    "\n",
    "    print(f\"Prediction: {y_prediction[0].item():0.4f}. True: {y_batch[0].item():0.4f}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}